\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand{\transparent@use}[1]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\citation{wiki_sm}
\citation{about_cms}
\citation{lhc1,lhc2,lhc2}
\citation{hl_lhc_tdr}
\citation{tdr_hgcal}
\citation{tdr_roc}
\citation{tdr_trig}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{mr}
\citation{wiki_sm}
\citation{wiki_sm}
\citation{higgs64,brout64}
\citation{lhc1,lhc2,lhc3}
\citation{lhc_ff}
\citation{lhc_ff}
\citation{amann02}
\citation{lhc_ff}
\citation{lhc_ff}
\@writefile{toc}{\contentsline {section}{\numberline {2}Particle physics at CERN}{2}{section.2}\protected@file@percent }
\newlabel{sec:cern}{{2}{2}{Particle physics at CERN}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Standard Model}{2}{subsection.2.1}\protected@file@percent }
\newlabel{sec:sm}{{2.1}{2}{Standard Model}{subsection.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Elementary particles in the Standard Model. Antiparticles are not shown. Figure taken from Ref. \cite  {wiki_sm}.\relax }}{3}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sm}{{1}{3}{Elementary particles in the Standard Model. Antiparticles are not shown. Figure taken from Ref. \cite {wiki_sm}.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Large Hadron Collider}{3}{subsection.2.2}\protected@file@percent }
\newlabel{sec:lhc}{{2.2}{3}{Large Hadron Collider}{subsection.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The CERN accelerator complex. \cite  {lhc_ff}.\relax }}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig:lhc}{{2}{4}{The CERN accelerator complex. \cite {lhc_ff}.\relax }{figure.caption.3}{}}
\citation{cern_wiki}
\citation{andre17}
\citation{hl_lhc_tdr}
\citation{hl_lhc_schedule}
\citation{hl_lhc_schedule}
\citation{Collaboration_2008,Bayatian:922757}
\citation{tq}
\citation{mr}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Future plans for the LHC \cite  {hl_lhc_schedule}.\relax }}{5}{figure.caption.4}\protected@file@percent }
\newlabel{fig:hl_lhc}{{3}{5}{Future plans for the LHC \cite {hl_lhc_schedule}.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Compact Muon Solenoid Experiment}{5}{subsection.2.3}\protected@file@percent }
\newlabel{sec:cms}{{2.3}{5}{Compact Muon Solenoid Experiment}{subsection.2.3}{}}
\citation{mr}
\citation{mr}
\citation{awr}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Coordinate system used by the CMS experiment. The x-axis points to the center of the LHC, the y-axis points upwards, and the z-axis points in counter-clockwise direction along the beam \cite  {mr}.\relax }}{6}{figure.caption.5}\protected@file@percent }
\newlabel{fig:cms_coord}{{4}{6}{Coordinate system used by the CMS experiment. The x-axis points to the center of the LHC, the y-axis points upwards, and the z-axis points in counter-clockwise direction along the beam \cite {mr}.\relax }{figure.caption.5}{}}
\citation{cms_overview}
\citation{cms_overview}
\citation{speer06}
\citation{Collaboration_2008,sonneveld18}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The CMS detector \cite  {cms_overview}.\relax }}{7}{figure.caption.6}\protected@file@percent }
\newlabel{fig:cms}{{5}{7}{The CMS detector \cite {cms_overview}.\relax }{figure.caption.6}{}}
\citation{Collaboration_2008,Bayatian:922757}
\citation{CMS:2010kua}
\citation{Collaboration_2008,Bayatian:922757}
\citation{solenoid}
\citation{about_cms}
\citation{Collaboration_2008,Bayatian:922757}
\citation{andre17}
\citation{mr}
\citation{tdr_trig}
\citation{awr,andre17}
\citation{db_hgcal}
\citation{hgcal}
\citation{zhang,anfreville,pileup}
\citation{phase2}
\citation{phase2}
\citation{si_rep,sipm_rep}
\citation{calo_rev}
\@writefile{toc}{\contentsline {section}{\numberline {3}High Granularity Calorimeter}{10}{section.3}\protected@file@percent }
\newlabel{chp:hgcal}{{3}{10}{High Granularity Calorimeter}{section.3}{}}
\citation{pp}
\citation{cms_endcap}
\citation{pp}
\citation{cms_endcap}
\citation{wigmans08}
\citation{wigmans08}
\newlabel{fig:pile}{{6a}{11}{Subfigure 6a}{subfigure.6.1}{}}
\newlabel{sub@fig:pile}{{(a)}{a}{Subfigure 6a\relax }{subfigure.6.1}{}}
\newlabel{fig:sn}{{6b}{11}{Subfigure 6b}{subfigure.6.2}{}}
\newlabel{sub@fig:sn}{{(b)}{b}{Subfigure 6b\relax }{subfigure.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces (a) Energy resolution $\sigma _\text  {eff}(E)/E$ for photons from Higgs boson decay for different integrated luminosities and pile-up as a function of pseudorapidity $\eta $. (b) Expectation of relative light collected S/S$_0$ of ECAL crystals for \SI {50}{GeV} electron showers as function of pseudorapidity $\eta $ for various aging conditions with S$_0$ being the light collected of unaged crystals. In 2016--2018 (Run 2) the integrated luminosity amounted to \SI {190}{fb^{-1}} whereas for High Luminosity an amount of \SIrange {3000}{4000}{fb^{-1}} is expected \cite  {phase2}.\relax }}{11}{figure.caption.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Calorimetry}{11}{subsection.3.1}\protected@file@percent }
\newlabel{sec:calo}{{3.1}{11}{Calorimetry}{subsection.3.1}{}}
\citation{wigmans08}
\newlabel{fig:hgcal_prof}{{7a}{12}{Subfigure 7a}{subfigure.7.1}{}}
\newlabel{sub@fig:hgcal_prof}{{(a)}{a}{Subfigure 7a\relax }{subfigure.7.1}{}}
\newlabel{fig:hgcal_real}{{7b}{12}{Subfigure 7b}{subfigure.7.2}{}}
\newlabel{sub@fig:hgcal_real}{{(b)}{b}{Subfigure 7b\relax }{subfigure.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces (a) Schematic cross section of an endcap \cite  {pp}. (b) Current calorimeter endcap inside the CMS detector \cite  {cms_endcap}.\relax }}{12}{figure.caption.13}\protected@file@percent }
\newlabel{eq:e_crit}{{5}{12}{Calorimetry}{equation.3.5}{}}
\citation{pdg}
\citation{pdg}
\citation{wigmans08}
\citation{wigmans08}
\citation{calo03}
\newlabel{fig:pdg_e}{{8a}{13}{Subfigure 8a}{subfigure.8.1}{}}
\newlabel{sub@fig:pdg_e}{{(a)}{a}{Subfigure 8a\relax }{subfigure.8.1}{}}
\newlabel{fig:pdg_g}{{8b}{13}{Subfigure 8b}{subfigure.8.2}{}}
\newlabel{sub@fig:pdg_g}{{(b)}{b}{Subfigure 8b\relax }{subfigure.8.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces (a) Fractional energy loss in lead by electrons and positrons as function of the energy. (b) Cross sections in lead by photons as function of energy. The shown processes are cross sections for pair production in electron field ($\kappa _e$), pair production in nuclear field ($\kappa _{nuc}$), photoelectric effect ($\sigma _{p.e.}$), Rayleigh scattering ($\sigma _{Rayleigh}$), and photo-nuclear absorption ($\sigma _{g.d.r}$). Figures taken from Ref. \cite  {pdg}.\relax }}{13}{figure.caption.14}\protected@file@percent }
\newlabel{fig:pdg}{{8}{13}{(a) Fractional energy loss in lead by electrons and positrons as function of the energy. (b) Cross sections in lead by photons as function of energy. The shown processes are cross sections for pair production in electron field ($\kappa _e$), pair production in nuclear field ($\kappa _{nuc}$), photoelectric effect ($\sigma _{p.e.}$), Rayleigh scattering ($\sigma _{Rayleigh}$), and photo-nuclear absorption ($\sigma _{g.d.r}$). Figures taken from Ref. \cite {pdg}.\relax }{figure.caption.14}{}}
\newlabel{eq:E}{{7}{13}{Calorimetry}{equation.3.7}{}}
\citation{calo03}
\citation{wigmans08}
\citation{wigmans08}
\citation{wigmans08}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Photon energy domains in which photoelectric effect, Compton scattering and pair production most likely occur as function of the atomic number Z. Image taken from Ref. \cite  {wigmans08}\relax }}{14}{figure.caption.15}\protected@file@percent }
\newlabel{fig:g_e_dom}{{9}{14}{Photon energy domains in which photoelectric effect, Compton scattering and pair production most likely occur as function of the atomic number Z. Image taken from Ref. \cite {wigmans08}\relax }{figure.caption.15}{}}
\citation{sensor}
\citation{sensor}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Distribution of energy fraction deposited in first 5 $X_0$ by 10 GeV electrons and photons showering in lead \cite  {wigmans08}.\relax }}{15}{figure.caption.16}\protected@file@percent }
\newlabel{fig:g_e_dist}{{10}{15}{Distribution of energy fraction deposited in first 5 $X_0$ by 10 GeV electrons and photons showering in lead \cite {wigmans08}.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Silicon Sensor}{15}{subsection.3.2}\protected@file@percent }
\newlabel{sec:sensors}{{3.2}{15}{Silicon Sensor}{subsection.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces 8" low density prototype HGCAL silicon sensor. The two calibration cells are located on a central vertical line in the upper half and lower half of the sensor.\relax }}{16}{figure.caption.17}\protected@file@percent }
\newlabel{fig:sens}{{11}{16}{8" low density prototype HGCAL silicon sensor. The two calibration cells are located on a central vertical line in the upper half and lower half of the sensor.\relax }{figure.caption.17}{}}
\newlabel{fig:cv}{{12a}{17}{Subfigure 12a}{subfigure.12.1}{}}
\newlabel{sub@fig:cv}{{(a)}{a}{Subfigure 12a\relax }{subfigure.12.1}{}}
\newlabel{fig:iv}{{12b}{17}{Subfigure 12b}{subfigure.12.2}{}}
\newlabel{sub@fig:iv}{{(b)}{b}{Subfigure 12b\relax }{subfigure.12.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces (a) Capacitance at 400V for LD 6" prototype sensor. (b) Single cell leakage current at 1000V for LD 6" prototype sensor. Figures taken from Ref. \cite  {sensor}.\relax }}{17}{figure.caption.18}\protected@file@percent }
\newlabel{fig:sens_plots}{{12}{17}{(a) Capacitance at 400V for LD 6" prototype sensor. (b) Single cell leakage current at 1000V for LD 6" prototype sensor. Figures taken from Ref. \cite {sensor}.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Readout Chip}{17}{subsection.3.3}\protected@file@percent }
\newlabel{sec:roc}{{3.3}{17}{Readout Chip}{subsection.3.3}{}}
\citation{tdr_roc}
\citation{tdr_roc}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The (packaged) HGCROC at scale. The silicon inside the package is even smaller.\relax }}{18}{figure.caption.19}\protected@file@percent }
\newlabel{fig:roc}{{13}{18}{The (packaged) HGCROC at scale. The silicon inside the package is even smaller.\relax }{figure.caption.19}{}}
\citation{tdr_hgcal}
\citation{tdr_hgcal}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Schematic architecture of HGCROCv2 \cite  {tdr_roc}.\relax }}{19}{figure.caption.20}\protected@file@percent }
\newlabel{fig:roc_schema}{{14}{19}{Schematic architecture of HGCROCv2 \cite {tdr_roc}.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Trigger Primitive Generator}{19}{subsection.3.4}\protected@file@percent }
\newlabel{subsec:tpg}{{3.4}{19}{Trigger Primitive Generator}{subsection.3.4}{}}
\citation{trig_algos}
\citation{tdr_hgcal}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces The CMS Phase-2 Level-1 Trigger system \cite  {tdr_hgcal}.\relax }}{20}{figure.caption.21}\protected@file@percent }
\newlabel{fig:trg}{{15}{20}{The CMS Phase-2 Level-1 Trigger system \cite {tdr_hgcal}.\relax }{figure.caption.21}{}}
\newlabel{fig:thr_algo}{{16a}{21}{Subfigure 16a}{subfigure.16.1}{}}
\newlabel{sub@fig:thr_algo}{{(a)}{a}{Subfigure 16a\relax }{subfigure.16.1}{}}
\newlabel{fig:bc_algo}{{16b}{21}{Subfigure 16b}{subfigure.16.2}{}}
\newlabel{sub@fig:bc_algo}{{(b)}{b}{Subfigure 16b\relax }{subfigure.16.2}{}}
\newlabel{fig:stc_algo}{{16c}{21}{Subfigure 16c}{subfigure.16.3}{}}
\newlabel{sub@fig:stc_algo}{{(c)}{c}{Subfigure 16c\relax }{subfigure.16.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Illustration of ECON-T algorithms for examplatory trigger cell occupancy. (a) Threshold (b) Best-Choice (c) Super Trigger Cell.\relax }}{21}{figure.caption.22}\protected@file@percent }
\newlabel{fig:stc}{{16}{21}{Illustration of ECON-T algorithms for examplatory trigger cell occupancy. (a) Threshold (b) Best-Choice (c) Super Trigger Cell.\relax }{figure.caption.22}{}}
\citation{si_rep,sipm_rep}
\citation{acm}
\citation{pd}
\@writefile{toc}{\contentsline {section}{\numberline {4}Readout Chip Characterization}{22}{section.4}\protected@file@percent }
\newlabel{chp:char}{{4}{22}{Readout Chip Characterization}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Process variation}{22}{subsection.4.1}\protected@file@percent }
\newlabel{sec:proc_var}{{4.1}{22}{Process variation}{subsection.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Analog front-end of HGCROC\relax }}{22}{figure.caption.23}\protected@file@percent }
\newlabel{fig:analogFE}{{17}{22}{Analog front-end of HGCROC\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Strategy}{23}{subsection.4.2}\protected@file@percent }
\newlabel{sec:strategy}{{4.2}{23}{Strategy}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Hardware}{23}{subsubsection.4.2.1}\protected@file@percent }
\newlabel{sec:hw}{{4.2.1}{23}{Hardware}{subsubsection.4.2.1}{}}
\newlabel{fig:rocchar}{{18a}{23}{Subfigure 18a}{subfigure.18.1}{}}
\newlabel{sub@fig:rocchar}{{(a)}{a}{Subfigure 18a\relax }{subfigure.18.1}{}}
\newlabel{fig:trophy}{{18b}{23}{Subfigure 18b}{subfigure.18.2}{}}
\newlabel{sub@fig:trophy}{{(b)}{b}{Subfigure 18b\relax }{subfigure.18.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Test boards attached to hexacontroller.\relax }}{23}{figure.caption.24}\protected@file@percent }
\newlabel{fig:hw}{{18}{23}{Test boards attached to hexacontroller.\relax }{figure.caption.24}{}}
\citation{i2c}
\citation{axi}
\citation{tdr_roc}
\citation{tdr_roc}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Software}{24}{subsubsection.4.2.2}\protected@file@percent }
\newlabel{sec:sw}{{4.2.2}{24}{Software}{subsubsection.4.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Software architecture of test systems. The client computer (left) sends configuration files to the hexacontorller server (right), which configures the ROCs and sends the data back to the client which stores it for later analysis.\relax }}{24}{figure.caption.25}\protected@file@percent }
\newlabel{fig:sw}{{19}{24}{Software architecture of test systems. The client computer (left) sends configuration files to the hexacontorller server (right), which configures the ROCs and sends the data back to the client which stores it for later analysis.\relax }{figure.caption.25}{}}
\citation{zmq}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Table of I$^2$C registers and their function \cite  {tdr_roc}.\relax }}{25}{figure.caption.26}\protected@file@percent }
\newlabel{fig:i2c_reg}{{20}{25}{Table of I$^2$C registers and their function \cite {tdr_roc}.\relax }{figure.caption.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Amount of bus read/write operations for different configuration files. The init.yaml file contains the initial configuration of the ROCs, while all other yaml-files are used to configure the ROC for certain tests. Because these files are executed with each run, a full test requires configuring the ROC with the almost identical configuration file several times in a row. The amount of successive configurations for testing puposes is indicated in paranthesis behind each configuration file.\relax }}{26}{table.caption.27}\protected@file@percent }
\newlabel{tab:bus}{{1}{26}{Amount of bus read/write operations for different configuration files. The init.yaml file contains the initial configuration of the ROCs, while all other yaml-files are used to configure the ROC for certain tests. Because these files are executed with each run, a full test requires configuring the ROC with the almost identical configuration file several times in a row. The amount of successive configurations for testing puposes is indicated in paranthesis behind each configuration file.\relax }{table.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Write cache saves state and avoids redundant writes. It is written to or querried via an address--value pair. The address consists of a tuple (R0,R1) and the value is a byte to be written to the specified ROC register.\relax }}{27}{figure.caption.28}\protected@file@percent }
\newlabel{fig:write_cache}{{21}{27}{Write cache saves state and avoids redundant writes. It is written to or querried via an address--value pair. The address consists of a tuple (R0,R1) and the value is a byte to be written to the specified ROC register.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Tests and results}{27}{subsection.4.3}\protected@file@percent }
\newlabel{sec:tests}{{4.3}{27}{Tests and results}{subsection.4.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Power consumption}{27}{subsubsection.4.3.1}\protected@file@percent }
\citation{ina250}
\citation{schematic:trophy}
\citation{al}
\citation{al}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Probe points}{28}{subsubsection.4.3.2}\protected@file@percent }
\citation{al}
\citation{al}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces ProbeDC measurements for one half across chips \cite  {al}.\relax }}{29}{figure.caption.29}\protected@file@percent }
\newlabel{fig:probeDC}{{22}{29}{ProbeDC measurements for one half across chips \cite {al}.\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces HGCROC calibration circuit. Figure is a zoomed excerpt of Fig.~\ref  {fig:analogFE}.\relax }}{29}{figure.caption.30}\protected@file@percent }
\newlabel{fig:calibCirc}{{23}{29}{HGCROC calibration circuit. Figure is a zoomed excerpt of Fig.~\ref {fig:analogFE}.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Pedestals}{29}{subsubsection.4.3.3}\protected@file@percent }
\newlabel{sec:ped}{{4.3.3}{29}{Pedestals}{subsubsection.4.3.3}{}}
\citation{tdr_roc}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Voltage at $CTEST$ as function of $CalDAC$ value \cite  {al}.\relax }}{30}{figure.caption.31}\protected@file@percent }
\newlabel{fig:intCtest}{{24}{30}{Voltage at $CTEST$ as function of $CalDAC$ value \cite {al}.\relax }{figure.caption.31}{}}
\newlabel{fig:pedRun1}{{25a}{31}{Subfigure 25a}{subfigure.25.1}{}}
\newlabel{sub@fig:pedRun1}{{(a)}{a}{Subfigure 25a\relax }{subfigure.25.1}{}}
\newlabel{fig:pedRun2}{{25b}{31}{Subfigure 25b}{subfigure.25.2}{}}
\newlabel{sub@fig:pedRun2}{{(b)}{b}{Subfigure 25b\relax }{subfigure.25.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Measurement of baseline pedestals.\relax }}{31}{figure.caption.32}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces a}}{31}{subfigure.25.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces b}}{31}{subfigure.25.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces ADC counts as a function of $Inv_{vref,trim}$.\relax }}{32}{figure.caption.33}\protected@file@percent }
\newlabel{fig:pedScan}{{26}{32}{ADC counts as a function of $Inv_{vref,trim}$.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.4}Shapers}{32}{subsubsection.4.3.4}\protected@file@percent }
\newlabel{sec:shaper}{{4.3.4}{32}{Shapers}{subsubsection.4.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.5}Analog-to-Digital Converters}{33}{subsubsection.4.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.6}Discriminators}{33}{subsubsection.4.3.6}\protected@file@percent }
\newlabel{fig:vref2d}{{27a}{34}{Subfigure 27a}{subfigure.27.1}{}}
\newlabel{sub@fig:vref2d}{{(a)}{a}{Subfigure 27a\relax }{subfigure.27.1}{}}
\newlabel{fig:sat2d}{{27b}{34}{Subfigure 27b}{subfigure.27.2}{}}
\newlabel{sub@fig:sat2d}{{(b)}{b}{Subfigure 27b\relax }{subfigure.27.2}{}}
\newlabel{fig:dyn_range2d}{{27c}{34}{Subfigure 27c}{subfigure.27.3}{}}
\newlabel{sub@fig:dyn_range2d}{{(c)}{c}{Subfigure 27c\relax }{subfigure.27.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces ADC counts as function of the global shaper parameters.\relax }}{34}{figure.caption.34}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces a}}{34}{subfigure.27.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces b}}{34}{subfigure.27.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces c}}{34}{subfigure.27.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces ADC count as a function of Phase parameter for two halves\relax }}{35}{figure.caption.35}\protected@file@percent }
\newlabel{fig:sampScan}{{28}{35}{ADC count as a function of Phase parameter for two halves\relax }{figure.caption.35}{}}
\newlabel{fig:inj2}{{29a}{35}{Subfigure 29a}{subfigure.29.1}{}}
\newlabel{sub@fig:inj2}{{(a)}{a}{Subfigure 29a\relax }{subfigure.29.1}{}}
\newlabel{fig:inj1}{{29b}{35}{Subfigure 29b}{subfigure.29.2}{}}
\newlabel{sub@fig:inj1}{{(b)}{b}{Subfigure 29b\relax }{subfigure.29.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Injection scans for two halves of a chip. The blue curve corresponds to the first half, orange to the second.\relax }}{35}{figure.caption.36}\protected@file@percent }
\newlabel{fig:inj}{{29}{35}{Injection scans for two halves of a chip. The blue curve corresponds to the first half, orange to the second.\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Conclusion}{36}{subsection.4.4}\protected@file@percent }
\citation{nielsen15}
\citation{fcholet17}
\citation{jahr15}
\citation{jahr15}
\@writefile{toc}{\contentsline {section}{\numberline {5}Convolutional Autoencoder Trigger Concept}{37}{section.5}\protected@file@percent }
\newlabel{chp:nn_tpg}{{5}{37}{Convolutional Autoencoder Trigger Concept}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Neural network}{37}{subsection.5.1}\protected@file@percent }
\newlabel{sec:nn}{{5.1}{37}{Neural network}{subsection.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Simple neural network architecture. Figure taken from Ref. \cite  {jahr15}.\relax }}{37}{figure.caption.37}\protected@file@percent }
\newlabel{fig:schema_nn}{{30}{37}{Simple neural network architecture. Figure taken from Ref. \cite {jahr15}.\relax }{figure.caption.37}{}}
\citation{colah_nn}
\newlabel{eq:single_activation}{{12}{38}{Neural network}{equation.5.12}{}}
\newlabel{eq:vec_activation}{{13}{38}{Neural network}{equation.5.13}{}}
\citation{menshawy18}
\citation{menshawy18}
\citation{Goodfellow16}
\citation{jordan_ae}
\newlabel{eq:mse}{{14}{39}{Neural network}{equation.5.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Autoencoder}{39}{subsubsection.5.1.1}\protected@file@percent }
\newlabel{sec:ae}{{5.1.1}{39}{Autoencoder}{subsubsection.5.1.1}{}}
\citation{convBlock}
\citation{convBlock}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Schematic of a five-hidden-layer deep undercomplete autoencoder network. Figure taken from Ref. \cite  {menshawy18}.\relax }}{40}{figure.caption.38}\protected@file@percent }
\newlabel{fig:autoenc}{{31}{40}{Schematic of a five-hidden-layer deep undercomplete autoencoder network. Figure taken from Ref. \cite {menshawy18}.\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Convolutional Neural Network}{40}{subsubsection.5.1.2}\protected@file@percent }
\newlabel{sec:cnn}{{5.1.2}{40}{Convolutional Neural Network}{subsubsection.5.1.2}{}}
\citation{lecun_mnist}
\citation{nielsen15}
\citation{wiki_mnist}
\citation{wiki_mnist}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Working principle of convolutional layers. One pixel value of the resulting feature map is a weighted sum of an image patch with the kernel values. Figure taken from Ref. \cite  {convBlock}.\relax }}{41}{figure.caption.39}\protected@file@percent }
\newlabel{fig:conv}{{32}{41}{Working principle of convolutional layers. One pixel value of the resulting feature map is a weighted sum of an image patch with the kernel values. Figure taken from Ref. \cite {convBlock}.\relax }{figure.caption.39}{}}
\newlabel{eq:conv}{{15}{41}{Convolutional Neural Network}{equation.5.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}MNIST dataset}{41}{subsubsection.5.1.3}\protected@file@percent }
\newlabel{sec:mnist}{{5.1.3}{41}{MNIST dataset}{subsubsection.5.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Subset of the MNIST handwritten digit dataset. Figure taken from Ref. \cite  {wiki_mnist}.\relax }}{42}{figure.caption.40}\protected@file@percent }
\newlabel{fig:mnist}{{33}{42}{Subset of the MNIST handwritten digit dataset. Figure taken from Ref. \cite {wiki_mnist}.\relax }{figure.caption.40}{}}
\citation{trig_algos}
\citation{trig_algos}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Concept studies}{43}{subsection.5.2}\protected@file@percent }
\newlabel{sec:concept}{{5.2}{43}{Concept studies}{subsection.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces Increase of trigger rate rate as a function of offline threshold for the three different compression algorithms of the ECON-T chip: Threshold, Super Trigger Cell, BestChoice. These algorithms have been presented in Sec.~\ref  {subsec:tpg}. Two further variants Coarse BestChoice first applies sorting and then selects the N largest values, BC+STC uses BestChoice in the ECAL and Super Trigger Cells in the HCAL, based on the observation that BestChoice works best for EM showers (small objects) and STC best for jets (larger objects). Table taken from Ref. \cite  {trig_algos}.\relax }}{44}{figure.caption.41}\protected@file@percent }
\newlabel{fig:trig_algo}{{34}{44}{Increase of trigger rate rate as a function of offline threshold for the three different compression algorithms of the ECON-T chip: Threshold, Super Trigger Cell, BestChoice. These algorithms have been presented in Sec.~\ref {subsec:tpg}. Two further variants Coarse BestChoice first applies sorting and then selects the N largest values, BC+STC uses BestChoice in the ECAL and Super Trigger Cells in the HCAL, based on the observation that BestChoice works best for EM showers (small objects) and STC best for jets (larger objects). Table taken from Ref. \cite {trig_algos}.\relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Elementary encoder unit}{45}{subsubsection.5.2.1}\protected@file@percent }
\newlabel{sec:generic_enc}{{5.2.1}{45}{Elementary encoder unit}{subsubsection.5.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Illustration of a neural network based HGCAL trigger primitive generator. Trigger cell data from three ROCs is sent to one ECON-T, where the data is concatenated and encoded to the latent representation of a module. This latent space is sent together with 20 other ECON-T encodings to the Stage-1 encoder, which, again, concatenates its inputs and encodes it. Stage-1 encodings are sent together with 29 other Stage-1 encodings to Stage-2, which concatenates its inputs and encodes it. The latent space of Stage-2 is the trigger primitive. ROC and ECON-T compression will be implemented in hardware, while Stage-1 and Stage-2 is implemented in firmware. Corresponding decoders will be implemented in software in order to train the network and monitor the outputs of each stage during inference.\relax }}{46}{figure.caption.42}\protected@file@percent }
\newlabel{fig:conc_arch}{{35}{46}{Illustration of a neural network based HGCAL trigger primitive generator. Trigger cell data from three ROCs is sent to one ECON-T, where the data is concatenated and encoded to the latent representation of a module. This latent space is sent together with 20 other ECON-T encodings to the Stage-1 encoder, which, again, concatenates its inputs and encodes it. Stage-1 encodings are sent together with 29 other Stage-1 encodings to Stage-2, which concatenates its inputs and encodes it. The latent space of Stage-2 is the trigger primitive. ROC and ECON-T compression will be implemented in hardware, while Stage-1 and Stage-2 is implemented in firmware. Corresponding decoders will be implemented in software in order to train the network and monitor the outputs of each stage during inference.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Illustration of convolutional autoencoder model. The encoder takes a $28\times 28$ input image, produces a $4\times 4$ latent space from which the decoder tries to reproduce the original image.\relax }}{47}{figure.caption.43}\protected@file@percent }
\newlabel{fig:cae1}{{36}{47}{Illustration of convolutional autoencoder model. The encoder takes a $28\times 28$ input image, produces a $4\times 4$ latent space from which the decoder tries to reproduce the original image.\relax }{figure.caption.43}{}}
\newlabel{fig:FCAE_expl}{{37a}{49}{Subfigure 37a}{subfigure.37.1}{}}
\newlabel{sub@fig:FCAE_expl}{{(a)}{a}{Subfigure 37a\relax }{subfigure.37.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces Examples of input images (first row), their latent space representation (middle row) and their reconstruction from the latent space (last row) for: (a) The fully convolutional autoencoder (FCAE) and (b) the convolutional autoencoder (CAE). The training progression of (b) can be seen in Fig.~\ref  {fig:cae16_train}\relax }}{49}{figure.caption.44}\protected@file@percent }
\newlabel{fig:CAE_expl}{{37}{49}{Examples of input images (first row), their latent space representation (middle row) and their reconstruction from the latent space (last row) for: (a) The fully convolutional autoencoder (FCAE) and (b) the convolutional autoencoder (CAE). The training progression of (b) can be seen in Fig.~\ref {fig:cae16_train}\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces Progression of the MSE loss on the train set (blue) and the test/validation set (orange) for CAE with 16 latent dimensions and \SI {1000} training epochs.\relax }}{50}{figure.caption.45}\protected@file@percent }
\newlabel{fig:cae16_train}{{38}{50}{Progression of the MSE loss on the train set (blue) and the test/validation set (orange) for CAE with 16 latent dimensions and \SI {1000} training epochs.\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces Reconstruction loss after 1000 training epochs as a function of inverse compression ratio of the CAE. Each data point corresponds to a five-hidden-layer deep undercomplete convolutional autoencoder trained on the MNIST handwritten digit dataset.\relax }}{50}{figure.caption.46}\protected@file@percent }
\newlabel{fig:latent_dim}{{39}{50}{Reconstruction loss after 1000 training epochs as a function of inverse compression ratio of the CAE. Each data point corresponds to a five-hidden-layer deep undercomplete convolutional autoencoder trained on the MNIST handwritten digit dataset.\relax }{figure.caption.46}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Split encoding}{51}{subsubsection.5.2.2}\protected@file@percent }
\newlabel{sec:latent_concat}{{5.2.2}{51}{Split encoding}{subsubsection.5.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Invariance in $\bm  {\phi }$}{51}{subsubsection.5.2.3}\protected@file@percent }
\newlabel{sec:inv_phi}{{5.2.3}{51}{Invariance in \texorpdfstring {$\bm {\phi }$}{p}}{subsubsection.5.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces Illustration of 4-Split model. Four similar encoding units with individual parameters produce four $2\times 2$ latent spaces, which are concatenated and fed to the same decoder architecture from the baseline model described in Sec. \ref  {sec:generic_enc}.\relax }}{52}{figure.caption.47}\protected@file@percent }
\newlabel{fig:4split}{{40}{52}{Illustration of 4-Split model. Four similar encoding units with individual parameters produce four $2\times 2$ latent spaces, which are concatenated and fed to the same decoder architecture from the baseline model described in Sec. \ref {sec:generic_enc}.\relax }{figure.caption.47}{}}
\newlabel{fig:f4s_expl}{{41a}{53}{Subfigure 41a}{subfigure.41.1}{}}
\newlabel{sub@fig:f4s_expl}{{(a)}{a}{Subfigure 41a\relax }{subfigure.41.1}{}}
\newlabel{fig:f4s_expl2}{{41b}{53}{Subfigure 41b}{subfigure.41.2}{}}
\newlabel{sub@fig:f4s_expl2}{{(b)}{b}{Subfigure 41b\relax }{subfigure.41.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {41}{\ignorespaces Examples of input images (first row), their latent space representation (middle row) and their reconstruction from latent space (last row) for: (a) Fully convolutional 4-Split (F4S) and (b) 4-Split (4S) models.\relax }}{53}{figure.caption.48}\protected@file@percent }
\newlabel{fig:4split_2}{{41}{53}{Examples of input images (first row), their latent space representation (middle row) and their reconstruction from latent space (last row) for: (a) Fully convolutional 4-Split (F4S) and (b) 4-Split (4S) models.\relax }{figure.caption.48}{}}
\newlabel{fig:latent4free}{{42a}{54}{Subfigure 42a}{subfigure.42.1}{}}
\newlabel{sub@fig:latent4free}{{(a)}{a}{Subfigure 42a\relax }{subfigure.42.1}{}}
\newlabel{fig:latent4tied}{{42b}{54}{Subfigure 42b}{subfigure.42.2}{}}
\newlabel{sub@fig:latent4tied}{{(b)}{b}{Subfigure 42b\relax }{subfigure.42.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {42}{\ignorespaces Latent space activation for same image fragment for 4-split with (a) individual weights and (b) shared weights.\relax }}{54}{figure.caption.49}\protected@file@percent }
\newlabel{fig:latents4}{{42}{54}{Latent space activation for same image fragment for 4-split with (a) individual weights and (b) shared weights.\relax }{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {43}{\ignorespaces Examples of input images (first row), their latent space representation (middle row) and their reconstruction from latent space (last row) for the 4-Split model with shared weights.\relax }}{54}{figure.caption.50}\protected@file@percent }
\newlabel{fig:4s_shared}{{43}{54}{Examples of input images (first row), their latent space representation (middle row) and their reconstruction from latent space (last row) for the 4-Split model with shared weights.\relax }{figure.caption.50}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Partial encoding}{55}{subsubsection.5.2.4}\protected@file@percent }
\newlabel{sec:part_enc}{{5.2.4}{55}{Partial encoding}{subsubsection.5.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {44}{\ignorespaces Example of $28\times 28$ digits randomly positioned inside a larger $56\times 56$ image of zeros. The digit is translated in integer steps in the range $0\rightarrow 27$ for x- and y-axes.\relax }}{55}{figure.caption.51}\protected@file@percent }
\newlabel{fig:rand_pos}{{44}{55}{Example of $28\times 28$ digits randomly positioned inside a larger $56\times 56$ image of zeros. The digit is translated in integer steps in the range $0\rightarrow 27$ for x- and y-axes.\relax }{figure.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {45}{\ignorespaces Illustration of the 16-Split model. The 16 encoder units have the same architecture as the 4-Split encoders, generating a four unit latent space from a $14\times 14$ input image patch. Thus, the decoder input latent space consists of $64$ ($16\times 4$) values, from which the original $56\times 56$ image is reconstructed. The inverse compression ratio of the 16-Split is the same (0.02) as those of the 4-Split (4S) and the baseline (CAE) model.\relax }}{56}{figure.caption.52}\protected@file@percent }
\newlabel{fig:16s}{{45}{56}{Illustration of the 16-Split model. The 16 encoder units have the same architecture as the 4-Split encoders, generating a four unit latent space from a $14\times 14$ input image patch. Thus, the decoder input latent space consists of $64$ ($16\times 4$) values, from which the original $56\times 56$ image is reconstructed. The inverse compression ratio of the 16-Split is the same (0.02) as those of the 4-Split (4S) and the baseline (CAE) model.\relax }{figure.caption.52}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.5}Trigger primitive information}{56}{subsubsection.5.2.5}\protected@file@percent }
\newlabel{sec:tp_inf}{{5.2.5}{56}{Trigger primitive information}{subsubsection.5.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {46}{\ignorespaces Examples of input images (first row), their latent space representation (middle row) and their reconstruction from latent space (last row) for the 16-Split model with shared weights.\relax }}{57}{figure.caption.53}\protected@file@percent }
\newlabel{fig:expl_16s}{{46}{57}{Examples of input images (first row), their latent space representation (middle row) and their reconstruction from latent space (last row) for the 16-Split model with shared weights.\relax }{figure.caption.53}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Training summary for different models, including number of trainable parameters for the entire model (encoder model), the training time per epoch and the saturated reconstruction loss (MSE) on the validation set after \SI {10000} epochs. The corresponding model architectures are detailed in Appendix~\ref  {app:nn_arch}, and their training loss curves are shown in Appendix~\ref  {app:nn_loss}.\relax }}{57}{table.caption.54}\protected@file@percent }
\newlabel{tab:sum}{{2}{57}{Training summary for different models, including number of trainable parameters for the entire model (encoder model), the training time per epoch and the saturated reconstruction loss (MSE) on the validation set after \SI {10000} epochs. The corresponding model architectures are detailed in Appendix~\ref {app:nn_arch}, and their training loss curves are shown in Appendix~\ref {app:nn_loss}.\relax }{table.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {47}{\ignorespaces Examples of input images (first row), their latent space representation (middle row) and their the predicted classification (red) from latent space compared to the true class (blue) of a digit (last row) for the 16-Split with classification head (16S-C).\relax }}{58}{figure.caption.55}\protected@file@percent }
\newlabel{fig:16s_class}{{47}{58}{Examples of input images (first row), their latent space representation (middle row) and their the predicted classification (red) from latent space compared to the true class (blue) of a digit (last row) for the 16-Split with classification head (16S-C).\relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {48}{\ignorespaces Examples of input images (first row), their latent space representation (middle row) and their the predicted regression of position (red circle) from latent space compared to the true position (blue circumference) of the center of a digit (last row) for the 16-Split with regression head (16S-R). Above the prediction, the euclidean distance, $\Delta r$, between truth and prediction is given.\relax }}{59}{figure.caption.56}\protected@file@percent }
\newlabel{fig:16reg}{{48}{59}{Examples of input images (first row), their latent space representation (middle row) and their the predicted regression of position (red circle) from latent space compared to the true position (blue circumference) of the center of a digit (last row) for the 16-Split with regression head (16S-R). Above the prediction, the euclidean distance, $\Delta r$, between truth and prediction is given.\relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {49}{\ignorespaces Examples for 16-Split trained with classification and regression heads at the same time. Examples (first row), latent spaces (second row), classification probability distribution (third row), and regression results (last row).\relax }}{61}{figure.caption.57}\protected@file@percent }
\newlabel{fig:16s_class_regr}{{49}{61}{Examples for 16-Split trained with classification and regression heads at the same time. Examples (first row), latent spaces (second row), classification probability distribution (third row), and regression results (last row).\relax }{figure.caption.57}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Comparison of performance for different ways to train the 16-Split model for three different types of objectives: reconstruction (MSE loss), classification (CCE loss, binary accuracy metric), and regression (MAPE loss). The tasks without brackets in a row have been trained first, after which the encoder parameters were not changed anymore during training. The task in brackets comes from training the decoder on this (fixed) encoder. When more than one objective is trained at the same time, relative loss weights $LW$ had to be specified which have been chosen somewhat arbitrarily, and could probably be tuned to get better performance.\relax }}{62}{table.caption.58}\protected@file@percent }
\newlabel{tab:16sum}{{3}{62}{Comparison of performance for different ways to train the 16-Split model for three different types of objectives: reconstruction (MSE loss), classification (CCE loss, binary accuracy metric), and regression (MAPE loss). The tasks without brackets in a row have been trained first, after which the encoder parameters were not changed anymore during training. The task in brackets comes from training the decoder on this (fixed) encoder. When more than one objective is trained at the same time, relative loss weights $LW$ had to be specified which have been chosen somewhat arbitrarily, and could probably be tuned to get better performance.\relax }{table.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {50}{\ignorespaces Asymmetric progression of two different losses (MAPE, CCE) as function of their contribution (encoder loss weight $LW$) to the global loss. A value of $-1$ corresponds to pure classification, $+1$ to pure regression.\relax }}{62}{figure.caption.59}\protected@file@percent }
\newlabel{fig:asym}{{50}{62}{Asymmetric progression of two different losses (MAPE, CCE) as function of their contribution (encoder loss weight $LW$) to the global loss. A value of $-1$ corresponds to pure classification, $+1$ to pure regression.\relax }{figure.caption.59}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.6}Information bottleneck}{63}{subsubsection.5.2.6}\protected@file@percent }
\newlabel{sec:inf_bott}{{5.2.6}{63}{Information bottleneck}{subsubsection.5.2.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Loss performance of different objectives after varying the inverse compression ratio $1/C$ (latent dimensions/input dimensions) of a model while keeping the rest of the architecture unchanged. Models are trained until saturation on either reconstruction, classification or regression alone (16S, 16S-C, 16S-R) or the encoders are trained on regression and classification, after which the encoder parameters are fixed and the reconstruction head is trained on top of this (16-RC). For each model the values corresponding to best classification accuracy are selected and summarized in the table. Models with larger capacity needed to be trained with an exponentially larger number of epochs in order to reach saturation level.\relax }}{63}{table.caption.61}\protected@file@percent }
\newlabel{tab:16latent}{{4}{63}{Loss performance of different objectives after varying the inverse compression ratio $1/C$ (latent dimensions/input dimensions) of a model while keeping the rest of the architecture unchanged. Models are trained until saturation on either reconstruction, classification or regression alone (16S, 16S-C, 16S-R) or the encoders are trained on regression and classification, after which the encoder parameters are fixed and the reconstruction head is trained on top of this (16-RC). For each model the values corresponding to best classification accuracy are selected and summarized in the table. Models with larger capacity needed to be trained with an exponentially larger number of epochs in order to reach saturation level.\relax }{table.caption.61}{}}
\newlabel{fig:sumMSE}{{51a}{64}{Subfigure 51a}{subfigure.51.1}{}}
\newlabel{sub@fig:sumMSE}{{(a)}{a}{Subfigure 51a\relax }{subfigure.51.1}{}}
\newlabel{fig:sumMAPE}{{51b}{64}{Subfigure 51b}{subfigure.51.2}{}}
\newlabel{sub@fig:sumMAPE}{{(b)}{b}{Subfigure 51b\relax }{subfigure.51.2}{}}
\newlabel{fig:sumCCE}{{51c}{64}{Subfigure 51c}{subfigure.51.3}{}}
\newlabel{sub@fig:sumCCE}{{(c)}{c}{Subfigure 51c\relax }{subfigure.51.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {51}{\ignorespaces Saturated loss value as a function of decoder input latent dimensions for the 16-Split encoder model trained with different heads and with different learning objectives. The curves correspond to the values summarized in Tab.~\ref  {tab:16latent}.\relax }}{64}{figure.caption.60}\protected@file@percent }
\newlabel{fig:sum16s}{{51}{64}{Saturated loss value as a function of decoder input latent dimensions for the 16-Split encoder model trained with different heads and with different learning objectives. The curves correspond to the values summarized in Tab.~\ref {tab:16latent}.\relax }{figure.caption.60}{}}
\citation{Steen2017}
\citation{Steen2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Discussion}{65}{subsection.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {52}{\ignorespaces Example of test beam data for sensor occupancy due to a shower induced by a \SI {250}{GeV} electron \cite  {Steen2017}.\relax }}{66}{figure.caption.62}\protected@file@percent }
\newlabel{fig:shower_expl}{{52}{66}{Example of test beam data for sensor occupancy due to a shower induced by a \SI {250}{GeV} electron \cite {Steen2017}.\relax }{figure.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {53}{\ignorespaces Confusion matrix showing prediction accuracy of true positives along the diagonal and accuracy of false positives in all other positions. The plot summarizes the classification results on the validation set for 16-split trained on regression and classification simultaneously. The x-axis shows the predicted digit (class) labels and the y-axis the actual labels.\relax }}{66}{figure.caption.63}\protected@file@percent }
\newlabel{fig:classif_distrib}{{53}{66}{Confusion matrix showing prediction accuracy of true positives along the diagonal and accuracy of false positives in all other positions. The plot summarizes the classification results on the validation set for 16-split trained on regression and classification simultaneously. The x-axis shows the predicted digit (class) labels and the y-axis the actual labels.\relax }{figure.caption.63}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {54}{\ignorespaces Box plot showing the median (orange) in its interquartile range (box) and outliers are marked by circles for 16-Split (trained on regression and classification simultaneously, and with a latent space of 128 decoder input dimensions) regression on the validation set: (a) The x-coordinate and (b) the y-coordinate. The positions are calculated from the center of the $28\times 28$ digit embedded in the $56\times 56$ image and cover the range (14,14) to (42, 42).\relax }}{67}{figure.caption.64}\protected@file@percent }
\newlabel{fig:residuals}{{54}{67}{Box plot showing the median (orange) in its interquartile range (box) and outliers are marked by circles for 16-Split (trained on regression and classification simultaneously, and with a latent space of 128 decoder input dimensions) regression on the validation set: (a) The x-coordinate and (b) the y-coordinate. The positions are calculated from the center of the $28\times 28$ digit embedded in the $56\times 56$ image and cover the range (14,14) to (42, 42).\relax }{figure.caption.64}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Summary \& Outlook}{68}{section.6}\protected@file@percent }
\citation{vlad20}
\citation{vlad20}
\citation{baydin18}
\citation{baydin18}
\@writefile{toc}{\contentsline {section}{Appendices}{69}{section*.65}\protected@file@percent }
\@writefile{toc}{\setcounter {tocdepth}{0}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Gradient Descent and Backpropagation}{69}{appendix.1.A}\protected@file@percent }
\newlabel{app:nn_train}{{A}{69}{Gradient Descent and Backpropagation}{appendix.1.A}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {55}{\ignorespaces Visualization of the gradient descent algorithm for a model with parameters $\Theta _0$ and $\Theta _1$. Figure taken from Ref. \cite  {vlad20}.\relax }}{69}{figure.caption.66}\protected@file@percent }
\newlabel{fig:grad_desc}{{55}{69}{Visualization of the gradient descent algorithm for a model with parameters $\Theta _0$ and $\Theta _1$. Figure taken from Ref. \cite {vlad20}.\relax }{figure.caption.66}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {56}{\ignorespaces Illustration of forward and backward pass and the components of the computational graph used during neural network training process. Biases are ignored. Figure taken from Ref. \cite  {baydin18}.\relax }}{70}{figure.caption.67}\protected@file@percent }
\newlabel{fig:bp}{{56}{70}{Illustration of forward and backward pass and the components of the computational graph used during neural network training process. Biases are ignored. Figure taken from Ref. \cite {baydin18}.\relax }{figure.caption.67}{}}
\newlabel{eq:del}{{17}{70}{Gradient Descent and Backpropagation}{equation.1.A.17}{}}
\newlabel{eq:del2}{{19}{70}{Gradient Descent and Backpropagation}{equation.1.A.19}{}}
\citation{pca}
\citation{Goodfellow16}
\@writefile{toc}{\contentsline {section}{\numberline {B}Principal Component Analysis}{71}{appendix.1.B}\protected@file@percent }
\newlabel{app:pca}{{B}{71}{Principal Component Analysis}{appendix.1.B}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Neural network model architectures}{72}{appendix.1.C}\protected@file@percent }
\newlabel{app:nn_arch}{{C}{72}{Neural network model architectures}{appendix.1.C}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces \textbf  {CAE}: Baseline convolutional autoencoder\relax }}{72}{table.caption.68}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces \textbf  {FCAE}: Fully convolutional autoencoder\relax }}{72}{table.caption.69}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces \textbf  {4S}: 4-Split\relax }}{73}{table.caption.70}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces \textbf  {F4S}: Fully convolutional 4-Split\relax }}{73}{table.caption.71}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces \textbf  {16S}: 16-Split\relax }}{74}{table.caption.72}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces \textbf  {16S-C}: 16-Split classifier head\relax }}{74}{table.caption.73}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces \textbf  {16S-R}: 16-Split regressor head\relax }}{74}{table.caption.74}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {D}Neural network training progression}{75}{appendix.1.D}\protected@file@percent }
\newlabel{app:nn_loss}{{D}{75}{Neural network training progression}{appendix.1.D}{}}
\newlabel{fig:loss4free}{{57a}{75}{Subfigure 57a}{subfigure.57.1}{}}
\newlabel{sub@fig:loss4free}{{(a)}{a}{Subfigure 57a\relax }{subfigure.57.1}{}}
\newlabel{fig:loss4tied}{{57b}{75}{Subfigure 57b}{subfigure.57.2}{}}
\newlabel{sub@fig:loss4tied}{{(b)}{b}{Subfigure 57b\relax }{subfigure.57.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {57}{\ignorespaces 4-split reconstruction loss for (a) free weights (b) shared weights trained over 50 epochs.\relax }}{75}{figure.caption.75}\protected@file@percent }
\newlabel{fig:16rloss}{{58a}{75}{Subfigure 58a}{subfigure.58.1}{}}
\newlabel{sub@fig:16rloss}{{(a)}{a}{Subfigure 58a\relax }{subfigure.58.1}{}}
\newlabel{fig:16closs}{{58b}{75}{Subfigure 58b}{subfigure.58.2}{}}
\newlabel{sub@fig:16closs}{{(b)}{b}{Subfigure 58b\relax }{subfigure.58.2}{}}
\newlabel{fig:16closs}{{58c}{75}{Subfigure 58c}{subfigure.58.3}{}}
\newlabel{sub@fig:16closs}{{(c)}{c}{Subfigure 58c\relax }{subfigure.58.3}{}}
\newlabel{fig:16closs}{{58d}{75}{Subfigure 58d}{subfigure.58.4}{}}
\newlabel{sub@fig:16closs}{{(d)}{d}{Subfigure 58d\relax }{subfigure.58.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {58}{\ignorespaces 16-split (a) Reconstruction loss (b) Regression loss (c) Classification loss (d) classification accuracy for a model trained over 50 epochs.\relax }}{75}{figure.caption.76}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {E}16-Split weight distributions}{76}{appendix.1.E}\protected@file@percent }
\newlabel{app:nn_weight}{{E}{76}{16-Split weight distributions}{appendix.1.E}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {59}{\ignorespaces 16-Split weight and bias distributions per layer. Encoder parameters and (a) Decoder (b) Classifier and (c) Regressor parameters each individually trained for 50 epochs.\relax }}{76}{figure.caption.77}\protected@file@percent }
\newlabel{fig:weights}{{59}{76}{16-Split weight and bias distributions per layer. Encoder parameters and (a) Decoder (b) Classifier and (c) Regressor parameters each individually trained for 50 epochs.\relax }{figure.caption.77}{}}
\bibstyle{plainurl}
\bibdata{ref}
\bibcite{cern_wiki}{1}
\bibcite{convBlock}{2}
\bibcite{hl_lhc_schedule}{3}
\bibcite{i2c}{4}
\bibcite{lhc_ff}{5}
\bibcite{solenoid}{6}
\bibcite{wiki_mnist}{7}
\bibcite{wiki_sm}{8}
\bibcite{pca}{9}
\bibcite{zmq}{10}
\bibcite{schematic:trophy}{11}
\bibcite{andre17}{12}
\bibcite{anfreville}{13}
\bibcite{hl_lhc_tdr}{14}
\bibcite{si_rep}{15}
\@writefile{toc}{\setcounter {tocdepth}{1}}
\@writefile{toc}{\contentsline {section}{References}{77}{section*.78}\protected@file@percent }
\bibcite{amann02}{16}
\bibcite{pileup}{17}
\bibcite{tdr_hgcal}{18}
\bibcite{db_hgcal}{19}
\bibcite{baydin18}{20}
\bibcite{lhc3}{21}
\bibcite{cms_endcap}{22}
\bibcite{sensor}{23}
\bibcite{lhc1}{24}
\bibcite{lhc2}{25}
\bibcite{fcholet17}{26}
\bibcite{about_cms}{27}
\bibcite{CMS:2010kua}{28}
\bibcite{Bayatian:922757}{29}
\bibcite{Collaboration_2008}{30}
\bibcite{phase2}{31}
\bibcite{pd}{32}
\bibcite{cms_overview}{33}
\bibcite{brout64}{34}
\bibcite{calo03}{35}
\bibcite{Goodfellow16}{36}
\bibcite{higgs64}{37}
\bibcite{jahr15}{38}
\bibcite{jordan_ae}{39}
\bibcite{sipm_rep}{40}
\bibcite{lecun_mnist}{41}
\bibcite{al}{42}
\bibcite{menshawy18}{43}
\bibcite{acm}{44}
\bibcite{nielsen15}{45}
\bibcite{colah_nn}{46}
\bibcite{pp}{47}
\bibcite{tq}{48}
\bibcite{mr}{49}
\bibcite{awr}{50}
\bibcite{trig_algos}{51}
\bibcite{tdr_trig}{52}
\bibcite{sonneveld18}{53}
\bibcite{speer06}{54}
\bibcite{Steen2017}{55}
\bibcite{calo_rev}{56}
\bibcite{pdg}{57}
\bibcite{ina250}{58}
\bibcite{tdr_roc}{59}
\bibcite{vlad20}{60}
\bibcite{wigmans08}{61}
\bibcite{axi}{62}
\bibcite{hgcal}{63}
\bibcite{zhang}{64}
